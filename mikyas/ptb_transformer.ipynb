{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "# Enable TF Eager execution\n",
    "from tensorflow.contrib.eager.python import tfe\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "# Other setup\n",
    "Modes = tf.estimator.ModeKeys\n",
    "\n",
    "# Setup some directories\n",
    "data_dir = os.path.expanduser(\"~/t2t/data\")\n",
    "tmp_dir = os.path.expanduser(\"~/t2t/tmp\")\n",
    "train_dir = os.path.expanduser(\"~/t2t/train\")\n",
    "checkpoint_dir = os.path.expanduser(\"~/t2t/checkpoints\")\n",
    "tf.gfile.MakeDirs(data_dir)\n",
    "tf.gfile.MakeDirs(tmp_dir)\n",
    "tf.gfile.MakeDirs(train_dir)\n",
    "tf.gfile.MakeDirs(checkpoint_dir)\n",
    "gs_data_dir = \"gs://tensor2tensor-data\"\n",
    "gs_ckpt_dir = \"gs://tensor2tensor-checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithmic_addition_binary40',\n",
       " 'algorithmic_addition_decimal40',\n",
       " 'algorithmic_cipher_shift200',\n",
       " 'algorithmic_cipher_shift5',\n",
       " 'algorithmic_cipher_vigenere200',\n",
       " 'algorithmic_cipher_vigenere5',\n",
       " 'algorithmic_identity_binary40',\n",
       " 'algorithmic_identity_decimal40',\n",
       " 'algorithmic_multiplication_binary40',\n",
       " 'algorithmic_multiplication_decimal40',\n",
       " 'algorithmic_reverse_binary40',\n",
       " 'algorithmic_reverse_binary40_test',\n",
       " 'algorithmic_reverse_decimal40',\n",
       " 'algorithmic_reverse_nlplike32k',\n",
       " 'algorithmic_reverse_nlplike8k',\n",
       " 'algorithmic_shift_decimal40',\n",
       " 'audio_timit_characters_tune',\n",
       " 'audio_timit_tokens8k_test',\n",
       " 'audio_timit_tokens8k_tune',\n",
       " 'gym_pong_random5k',\n",
       " 'gym_pong_trajectories_from_policy',\n",
       " 'image_celeba',\n",
       " 'image_cifar10',\n",
       " 'image_cifar100',\n",
       " 'image_cifar100_plain',\n",
       " 'image_cifar100_plain8',\n",
       " 'image_cifar100_plain_gen',\n",
       " 'image_cifar100_tune',\n",
       " 'image_cifar10_plain',\n",
       " 'image_cifar10_plain8',\n",
       " 'image_cifar10_plain_gen',\n",
       " 'image_cifar10_tune',\n",
       " 'image_fashion_mnist',\n",
       " 'image_fsns',\n",
       " 'image_imagenet',\n",
       " 'image_imagenet224',\n",
       " 'image_imagenet32',\n",
       " 'image_imagenet64',\n",
       " 'image_imagenet64_gen',\n",
       " 'image_mnist',\n",
       " 'image_mnist_tune',\n",
       " 'image_ms_coco_characters',\n",
       " 'image_ms_coco_tokens32k',\n",
       " 'image_text_ms_coco',\n",
       " 'img2img_celeba',\n",
       " 'img2img_celeba64',\n",
       " 'img2img_cifar10',\n",
       " 'img2img_cifar100',\n",
       " 'img2img_imagenet',\n",
       " 'languagemodel_lm1b32k',\n",
       " 'languagemodel_lm1b8k_packed',\n",
       " 'languagemodel_lm1b_characters',\n",
       " 'languagemodel_lm1b_characters_packed',\n",
       " 'languagemodel_ptb10k',\n",
       " 'languagemodel_ptb_characters',\n",
       " 'languagemodel_wiki_noref_v8k_l16k',\n",
       " 'languagemodel_wiki_noref_v8k_l1k',\n",
       " 'languagemodel_wiki_scramble_l128',\n",
       " 'languagemodel_wiki_scramble_l1k',\n",
       " 'languagemodel_wiki_xml_v8k_l1k',\n",
       " 'languagemodel_wiki_xml_v8k_l4k',\n",
       " 'librispeech',\n",
       " 'librispeech_clean',\n",
       " 'librispeech_clean_small',\n",
       " 'librispeech_noisy',\n",
       " 'librispeech_train_full_test_clean',\n",
       " 'multinli_matched',\n",
       " 'multinli_mismatched',\n",
       " 'ocr_test',\n",
       " 'parsing_english_ptb16k',\n",
       " 'parsing_english_ptb8k',\n",
       " 'parsing_icelandic16k',\n",
       " 'programming_desc2code_cpp',\n",
       " 'programming_desc2code_py',\n",
       " 'sentiment_imdb',\n",
       " 'summarize_cnn_dailymail32k',\n",
       " 'text2text_tmpdir',\n",
       " 'translate_encs_wmt32k',\n",
       " 'translate_encs_wmt_characters',\n",
       " 'translate_ende_wmt32k',\n",
       " 'translate_ende_wmt32k_packed',\n",
       " 'translate_ende_wmt8k',\n",
       " 'translate_ende_wmt8k_packed',\n",
       " 'translate_ende_wmt_bpe32k',\n",
       " 'translate_ende_wmt_characters',\n",
       " 'translate_enfr_wmt32k',\n",
       " 'translate_enfr_wmt32k_packed',\n",
       " 'translate_enfr_wmt8k',\n",
       " 'translate_enfr_wmt_characters',\n",
       " 'translate_enfr_wmt_small32k',\n",
       " 'translate_enfr_wmt_small8k',\n",
       " 'translate_enfr_wmt_small_characters',\n",
       " 'translate_enmk_setimes32k',\n",
       " 'translate_enmk_setimes_characters',\n",
       " 'translate_enzh_wmt32k',\n",
       " 'translate_enzh_wmt8k',\n",
       " 'video_twentybn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems.available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not downloading, file already found: /home/mtdesta/t2t/tmp/simple-examples.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:10,913] Not downloading, file already found: /home/mtdesta/t2t/tmp/simple-examples.tgz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping generator because outputs files exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:11,724] Skipping generator because outputs files exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not downloading, file already found: /home/mtdesta/t2t/tmp/simple-examples.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:11,725] Not downloading, file already found: /home/mtdesta/t2t/tmp/simple-examples.tgz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping generator because outputs files exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:12,473] Skipping generator because outputs files exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping shuffle because output files exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:12,475] Skipping shuffle because output files exist\n"
     ]
    }
   ],
   "source": [
    "# Fetch the MNIST problem\n",
    "ptb_problem = problems.problem(\"languagemodel_ptb10k\")\n",
    "# The generate_data method of a problem will download data and process it into\n",
    "# a standard format ready for training and evaluation.\n",
    "ptb_problem.generate_data(data_dir, tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aligned',\n",
       " 'attention_lm',\n",
       " 'attention_lm_moe',\n",
       " 'basic_autoencoder',\n",
       " 'basic_conv_gen',\n",
       " 'basic_discrete_autoencoder',\n",
       " 'basic_fc_relu',\n",
       " 'byte_net',\n",
       " 'cycle_gan',\n",
       " 'diagonal_neural_gpu',\n",
       " 'gene_expression_conv',\n",
       " 'imagetransformer',\n",
       " 'imagetransformer2d',\n",
       " 'imagetransformer_moe',\n",
       " 'img2img_transformer',\n",
       " 'lstm_encoder',\n",
       " 'lstm_seq2seq',\n",
       " 'lstm_seq2seq_attention',\n",
       " 'lstm_seq2seq_attention_bidirectional_encoder',\n",
       " 'lstm_seq2seq_bidirectional_encoder',\n",
       " 'multi_model',\n",
       " 'neural_gpu',\n",
       " 'resnet',\n",
       " 'revnet',\n",
       " 'shake_shake',\n",
       " 'slice_net',\n",
       " 'super_lm',\n",
       " 'transformer',\n",
       " 'transformer_ae',\n",
       " 'transformer_encoder',\n",
       " 'transformer_moe',\n",
       " 'transformer_revnet',\n",
       " 'transformer_sketch',\n",
       " 'transformer_symshard',\n",
       " 'vanilla_gan',\n",
       " 'xception']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', ('symbol', 10000)), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:12,539] Setting T2TModel mode to 'train'\n"
     ]
    }
   ],
   "source": [
    "#hparams.hidden_size = 64\n",
    "model_name = \"transformer\"\n",
    "hparams_set = \"transformer_small\"\n",
    "\n",
    "\n",
    "hparams = trainer_lib.create_hparams(hparams_set, data_dir=data_dir, problem_name=\"languagemodel_ptb10k\")\n",
    "model = registry.model(model_name)(hparams, Modes.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from /home/mtdesta/t2t/data/languagemodel_ptb10k-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:12,570] Reading data files from /home/mtdesta/t2t/data/languagemodel_ptb10k-train*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:12,578] partition: 0 num_data_files: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from /home/mtdesta/t2t/data/languagemodel_ptb10k-train*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:13,175] Reading data files from /home/mtdesta/t2t/data/languagemodel_ptb10k-train*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:13,180] partition: 0 num_data_files: 10\n"
     ]
    }
   ],
   "source": [
    "@tfe.implicit_value_and_gradients\n",
    "def loss_fn(features):\n",
    "  _, losses = model(features)\n",
    "  return losses[\"training\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "max_num_of_words = 150\n",
    "ptb_train_dataset = ptb_problem.dataset(Modes.TRAIN, data_dir)\n",
    "ptb_train_dataset.output_shapes[\"targets\"] = [max_num_of_words]\n",
    "ptb_train_dataset = ptb_problem.dataset(Modes.TRAIN, data_dir)\n",
    "ptb_train_dataset = ptb_train_dataset.repeat(None).padded_batch(BATCH_SIZE, ptb_train_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PaddedBatchDataset shapes: {targets: (?, ?)}, types: {targets: tf.int64}>\n"
     ]
    }
   ],
   "source": [
    "print(ptb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:13,288] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Transforming 'targets' with symbol_modality_10000_256.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:13,291] Transforming 'targets' with symbol_modality_10000_256.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:13,334] Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with symbol_modality_10000_256.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:13,491] Transforming body output with symbol_modality_10000_256.top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mtdesta/tensorflow_1.6/lib/python3.5/site-packages/tensor2tensor/layers/common_layers.py:1717: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:13,822] From /home/mtdesta/tensorflow_1.6/lib/python3.5/site-packages/tensor2tensor/layers/common_layers.py:1717: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 8.803\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:14,477] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:15,273] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:15,947] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:16,637] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:17,308] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:18,023] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:18,723] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:19,384] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:20,066] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:20,836] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS =10\n",
    "\n",
    "for count, example in enumerate(tfe.Iterator(ptb_train_dataset)):\n",
    "  example[\"targets\"] = tf.reshape(example[\"targets\"], [BATCH_SIZE, -1, 1, 1])  # Make it 4D.\n",
    "  loss, gv = loss_fn(example)\n",
    "  optimizer.apply_gradients(gv)\n",
    "\n",
    "  if count % 50 == 0:\n",
    "    print(\"Step: %d, Loss: %.3f\" % (count, loss.numpy()))\n",
    "  if count >= NUM_STEPS:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,604] Setting T2TModel mode to 'eval'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,606] Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,606] Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,607] Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,608] Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,609] Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading data files from /home/mtdesta/t2t/data/languagemodel_ptb10k-dev*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,610] Reading data files from /home/mtdesta/t2t/data/languagemodel_ptb10k-dev*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:partition: 0 num_data_files: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,613] partition: 0 num_data_files: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,630] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,679] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,726] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,768] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,816] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,854] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,895] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,942] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:21,983] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,041] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,090] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,136] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,177] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,225] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,268] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,308] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,350] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,392] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,436] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,474] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,518] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,561] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,598] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,652] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,699] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,740] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,781] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,821] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,865] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,908] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,944] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:22,988] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,035] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,079] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,128] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,169] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,211] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,253] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,293] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,335] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,375] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,417] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,462] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,506] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,551] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,598] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,640] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,683] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,730] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,770] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,823] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,867] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,908] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,947] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:23,988] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,035] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,081] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,127] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,167] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,222] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,270] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,315] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,358] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,409] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,457] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,512] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,558] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,606] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,647] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,687] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,730] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,777] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,817] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,861] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,905] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,947] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:24,996] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,035] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,082] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,130] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,177] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,218] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,264] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,301] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,345] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,387] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,427] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,478] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,528] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,568] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,604] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,648] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,698] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,744] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,795] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,841] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,887] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,937] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:25,982] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,026] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,070] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,111] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,148] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,189] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,234] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,277] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,324] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,364] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,404] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,448] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,493] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,541] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,579] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,623] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,664] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,700] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,744] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,791] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,832] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,881] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,930] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:26,975] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,026] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,072] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,119] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,168] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,207] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,249] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,292] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,332] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,375] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,420] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,459] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,507] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,551] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,595] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,638] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,679] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,719] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,776] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,823] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,871] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,912] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:27,959] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,009] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,046] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,092] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,136] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,177] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,222] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,260] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,313] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,359] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,399] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,442] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,486] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,525] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,566] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,614] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,657] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,695] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,739] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,786] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,835] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,881] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,928] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:28,970] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,014] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,057] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,104] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,152] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,205] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,253] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,295] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,337] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,379] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,422] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,467] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,514] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,554] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,595] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,645] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,688] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,739] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,785] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,828] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,873] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,913] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,951] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:29,998] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,044] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,093] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,139] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,183] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,219] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,267] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,310] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,353] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,396] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-03 15:25:30,434] Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batch_size_multiplier', 1), ('input_modality', {}), ('input_space_id', 0), ('loss_multiplier', 1.0), ('stop_at_eos', 1), ('target_modality', <tensor2tensor.layers.modalities.SymbolModality object at 0x7ff12dce75c0>), ('target_space_id', 0), ('vocabulary', {'targets': <tensor2tensor.data_generators.text_encoder.TokenTextEncoder object at 0x7ff12dce7320>}), ('was_copy', False), ('was_reversed', False)]\n",
      "approx_bleu_score: 0.04\n",
      "neg_log_perplexity: -7.08\n"
     ]
    }
   ],
   "source": [
    "model.set_mode(Modes.EVAL)\n",
    "ptb_eval_dataset = ptb_problem.dataset(Modes.EVAL, data_dir)\n",
    "\n",
    "# Create eval metric accumulators for accuracy (ACC) and accuracy in\n",
    "# top 5 (ACC_TOP5)\n",
    "metrics_accum, metrics_result = metrics.create_eager_metrics(\n",
    "    [metrics.Metrics.NEG_LOG_PERPLEXITY, metrics.Metrics.APPROX_BLEU])\n",
    "\n",
    "for count, example in enumerate(tfe.Iterator(ptb_eval_dataset)):\n",
    "  if count >= 200:\n",
    "    break\n",
    "\n",
    "  # Make the inputs and targets 4D\n",
    "  #example[\"inputs\"] = tf.reshape(example[\"inputs\"], [1, -1, 32, 1])\n",
    "  example[\"targets\"] = tf.reshape(example[\"targets\"], [1, -1, 1, 1])\n",
    "\n",
    "  # Call the model\n",
    "  predictions, _ = model(example)\n",
    "\n",
    "  # Compute and accumulate metrics\n",
    "  metrics_accum(predictions, example[\"targets\"])\n",
    "\n",
    "# Print out the averaged metric values on the eval data\n",
    "for name, val in metrics_result().items():\n",
    "  print(\"%s: %.2f\" % (name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}